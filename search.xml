<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[交叉熵损失函数]]></title>
    <url>%2F2019%2F10%2F17%2Fml-cross-entropy-loss-function%2F</url>
    <content type="text"><![CDATA[交叉熵损失函数(逻辑回归)：$$J(\theta)=-\frac{1}{N}\sum_{i=1}^{N}y^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))$$ $J(\theta)$对$\theta$的偏导数(用于诸如梯度下降法等优化算法的参数更新)： $$\frac{\partial}{\partial\theta_j}J(\theta)=\frac{1}{N}\sum_{i=1}^{N}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ 1. 交叉熵损失函数的数学原理在二分类问题模型中，真实样本的标签为$[0,1]$，分别表示负类和正类。模型的最后通常会经过一个Sigmoid函数，输出一个概率值，这个概率值反映了预测为正类的可能性。Sigmod函数的输出表征了当前样本标签为1的概率：$$ \hat{y}=P(y=1 \mid x)$$对于样本标签为0的概率可以表达为：$$ 1-\hat{y}=P(y=0\mid x)$$从极大似然性的角度将上面两个公式进行融合得到：$$ P(y\mid x)=\hat{y}^y\cdot(1-\hat{y})^{1-y}$$当真实标签为1或者0时，依据上式可分别得到：$$ P(y=1 \mid x)=\hat{y}$$$$ P(y=0\mid x)=1-\hat{y}$$两种情况下概率表达式完全一样。 对于$P(y \mid x)$，我们希望其越大越好。因为$log$运算不会影响函数本身的单调性，所以，对$P(y \mid x)$进行对数运算。则有：$$\begin {aligned}log(P(y\mid x))&amp;=log(\hat{y}^y\cdot(1-\hat{y})^{1-y})\\&amp;=ylog(\hat{y})+(1-y)log(1-\hat{y})\end {aligned}$$我们希望 $log(P(y \mid x))$越大越好，即$-log(P(y \mid x))$越小越好。对于N个样本的总的损失函数为：$$ loss=-\frac{1}{N}\sum_{i=1}^{N}y^{(i)}log(\hat{y}^{(i)})+(1-y^{(i)})log(1-\hat{y}^{(i)})$$ 2. 交叉熵损失函数求导我们一共有N组样本，$(x^{(i)},y^{(i)})$表示第$i$组样本及其对应的类别标记。其中，$x^{(i)}=(1,x_1^{(i)},x_2^{(i)},…,x_m^{(i)})^T$，$y^{(i)}$为表示类别的数值。 logistic回归（二分类问题）中，$y^{(i)}$取0或1； softmax回归（多分类问题）中，$y^{(i)}$取值为$1~k$中的一个值表示一个类别 输入样本数据$x^{(i)}=(1,x_1^{(i)},x_2^{(i)},…,x_m^{(i)})^T$，$y^{(i)}$，模型参数为$\theta=(\theta_0,\theta_1,\theta_3,…,\theta_m)^T$，因此有：$$ \theta^Tx^{(i)}:=\theta_0+\theta_1x_1^{(i)}+…+\theta_mx_m^{(i)}$$ 假设函数(hypothesis function)定义为：$$ h_\theta(x^{(i)})=\frac{1}{1+e^{-\theta^Tx^{(i)}}}$$用对于第一节得出的损失函数$ h_\theta(x^{(i)})$取代$\hat{y}^{(i)}$，就可以得到在机器学习中常见的交叉熵损失函数的表达式：$$ J(\theta)=-\frac{1}{N}\sum_{i=1}^{N}y^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))$$ $J(\theta)$对$\theta$的偏导数涉及到矩阵和向量的倒数，对于交叉熵损失函数$J(\theta)$，其中：$$ log(h_\theta(x^{(i)}))=log\frac{1}{1+e^{-\theta^Tx^{(i)}}}=-log(1+e^{-\theta^Tx^{(i)}})$$$$\begin {aligned}log(1-h_\theta(x^{(i)}))&amp;=log(1-\frac{1}{1+e^{-\theta^Tx^{(i)}}})=log\frac{e^{-\theta^Tx^{(i)}}}{1+e^{-\theta^Tx^{(i)}}}\\&amp;=log(e^{-\theta^Tx^{(i)}})-log(1+e^{-\theta^Tx^{(i)}})\\&amp;=-\theta^Tx^{(i)}-log(1+e^{-\theta^Tx^{(i)}})\end {aligned}$$由此可以得到：$$\begin{aligned}J(\theta)&amp;=-\frac{1}{N}\sum_{i=1}^{N}[-y^{(i)}(log(1+e^{-\theta^Tx^{(i)}}))+(1-y^{(i)})(-\theta^Tx^{(i)}-log(1+e^{-\theta^Tx^{(i)}}))]\\&amp;=-\frac{1}{N}\sum_{i=1}^{N}[y^{(i)}\theta^Tx^{(i)}-\theta^Tx^{(i)}-log(1+e^{-\theta^Tx^{(i)}})]\\&amp;=-\frac{1}{N}\sum_{i=1}^{N}[y^{(i)}\theta^Tx^{(i)}-log(e^{\theta^Tx^{(i)}})-log(1+e^{-\theta^Tx^{(i)}})]\\&amp;=-\frac{1}{N}\sum_{i=1}^{N}[y^{(i)}\theta^Tx^{(i)}-log(1+e^{\theta^Tx^{(i)}})]\end{aligned}$$再计算$J(\theta)$对$\theta_j$的偏导数:$$\begin{aligned}\frac{\partial}{\partial\theta_j}J(\theta)&amp;=\frac{\partial}{\partial\theta_j}(\frac{1}{N}\sum_{i=1}^{N}[log(1+e^{\theta^Tx^{(i)}})-y^{(i)}\theta^Tx^{(i)}])\\&amp;=\frac{1}{N}\sum_{i=1}^{N}[\frac{\partial}{\partial\theta_j}log(1+e^{\theta^Tx^{(i)}})-\frac{\partial}{\partial\theta_j}(y^{(i)}\theta^Tx^{(i)})]\\&amp;=\frac{1}{N}\sum_{i=1}^{N}[\frac{x_j^{(i)}e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}-y^{(i)}x_j^{(i)}]\\&amp;=\frac{1}{N}\sum_{i=1}^{N}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\end{aligned}$$ 3.为什么用交叉熵作为损失函数在深度学习中，我们常用的损失函数是二次函数$L=\frac{(y-\hat{y})^2}{2}$，若激活函数使用的是sigmoid函数，则$\hat{y}=\sigma(z)$，其中$z=wx+b$。采用链式法则求导则有：$$\frac{\partial L}{\partial w}=(\hat{y}-y)\sigma(z)’x\\frac{\partial L}{\partial b}=(\hat{y}-y)\sigma(z)’$$由上面两个式子可以看出，损失函数的梯度都与sigmoid函数的梯度有关，而simoid函数的两端存在梯度消失问题。 使用交叉熵作为损失函数，其倒数形式为： $$\frac{\partial L}{\partial w}=\frac{1}{N}\sum_i{x(\sigma(z)-y)}\\frac{\partial L}{\partial b}=\frac{1}{N}\sum_i{(\sigma(z)-y)}$$ 使用交叉熵作为损失函数，其反向传播梯度与sigmoid函数的梯度无关，从而避免了梯度消失的问题。 参考文献 简单的交叉熵损失函数，你真的懂了吗？ 交叉熵损失函数求导推导]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>交叉熵</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++资源管理和智能指针]]></title>
    <url>%2F2019%2F10%2F16%2Fcpp-resource-management%2F</url>
    <content type="text"><![CDATA[C++中最常使用的资源就是内存，其他常见的还包括文件句柄、互斥锁(mutex lock)、数据库连接、以及网络socket等。在计算机系统中，这些系统资源是有限的，所以在使用完资源后必须要进行释放。本文主要记录C++中的资源管理的机制RAII(Resource Acquisition Is Initialization)以及一些要点。 1. C++资源管理我们在使用系统资源时，都必须遵循一个步骤：申请资源-&gt;使用资源-&gt;释放资源。资源只有申请后才能使用，使用完成后必须要释放，如果不释放就会造成资源泄露。比如，我们使用malloc/new开辟的内存资源，必须要通过free/delete进行释放，否则就会造成内存泄漏。所以，在编程的时候malloc和free、new和delete总是匹配的。 1234567FILE* file = fopen(fn,'r'); // 申请资源// 使用资源if(!f()) return; // f()失败，返回// ... if(!g()) return; // g()失败，返回// ...fclose(file); // 释放资源 在上述代码中，存在着因某些操作失败而提前返回的现象，这时就会跳过资源释放的操作，造成资源泄露。对于简单的代码可以在不同的位置重复书写释放资源的代码，如果项目中有异常处理或者需要管理的资源有多个，重复书写资源释放的代码会造成代码冗余且后期难以维护。 12345678910111213141516FILE* file = fopen(fn,'r'); // 申请资源// 使用资源try&#123; if(!f()) &#123;fclose(file); return;&#125; // f()失败，返回 // ... if(!g()) &#123;fclose(file); return;&#125; // g()失败，返回 // ...&#125;catch(...)&#123; fclose(file); throw;&#125;fclose(file); // 释放资源 2. RAII的机制在C++中，定义在栈上的局部对象的创建和销毁是由系统自动完成的。我们在某个作用域中定义和使用局部对象，当控制流程超出作用域的控制范围时，系统会自动调用析构函数来销毁该对象。 RAII是C++语言中一种资源管理的常用规范，其基本思路是用类来封装资源，在类的构造函数中获取资源，在类的析构函数中释放资源。使用的时候，把资源管理类实例化为一个对象，当类超出作用域的时候，就会调用类的析构函数对资源进行释放。 12345678910class FileHandle&#123;public: FileHandle(char const* fn, char const* t)&#123; f = fopen(fn,t);&#125; ~FileHandle()&#123;fclose(f);&#125;private: FileHandle(FileHandle const&amp;); //复制构造函数 FileHandle&amp; operate= (FileHandle const&amp;);//赋值运算符 FILE* f;&#125; FileHandle类的构造函数调用fopen()获取资源；FileHandle类的析构函数调用fclose()释放资源。FileHandle对象代表的是资源，不具有拷贝语义，因此需要将复制构造函数和赋值运算符声明为私有成员，这样可以避免在进行资源对象作为参数传递时发生值的复制，造成访问冲突。 3. 智能指针在C++中，我们创建一个指向某个对象的普通指针，在使用完这个指针之后需要进行删除，否则会造成一个悬挂指针，导致内存泄漏。 智能指针和普通指针的区别在于智能指针实际上是对普通指针加了一层封装机制，这样的一层封装机制的目的是为了使得智能指针可以方便的管理一个对象的生命期。智能指针就是RAII的实现范例，专门用来动态的分配内存。它提供所有普通指针提供的接口，却很少发生异常。在构造中，它分配内存，当离开作用域时，它会自动释放已分配的内存。 NOTE: C++11的智能指针的构造函数都有explicit关键词修饰，表明它不能被隐式的进行类型转换。 C++11中有三个智能指针：unique_prt、shared_ptr和weak_ptr。 3.1 unique_prtunique_prt是一个独享所有权的智能指针 3.2 shared_ptrshared_ptr使用了计数机制来表明资源被几个指针共享。 3.3 weak_ptrweak_ptr是用来解决shared_ptr相互引用时的死锁问题。 weak_ptr相当于shared_ptr的辅助指针，所以主要的智能指针只有shared_ptr和weak_ptr。 参考文章 &amp; 资源链接 RAII用法详解 智能指针]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>RAII</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis编程环境]]></title>
    <url>%2F2019%2F10%2F16%2Fredis-programming-guide%2F</url>
    <content type="text"><![CDATA[1 Redis Python编程Python使用Redis非常简单，可以通过pip install redis在环境中安装编程需要的API。下面是一个简单的实例，利用Redis存储数值、字符串和图像。 123456789101112131415161718192021222324252627282930313233343536import cv2import redisimport structimport numpy as npdef toRedis(array): ''' Encode ndarry 'array' to bytes ''' # 1. get shape of Numpy array and encode h,w = array.shape shape = struct.pack('&gt;II',h,w) # '&gt;'表示大端，'I'表示4个字节的unsigned int，'II'表示8字节的unsigned int # 2. append the Numpy array as bytes to the shape encode = shape+array.tobytes() return encodedef fromRedis(encode): # 4. extract the shape of the Numpy array from the string h,w = struct.unpack('&gt;II',encode[:8]) # extract data and repopulate Numpy array, reshape to original shape array = np.frombuffer(encode,dtype=np.uint8,offset=8).reshape(h,w) return arrayif __name__=='__main__': r = redis.Redis(host='127.0.0.1',port=6379) img = cv2.imread('./oil11_2.bmp',cv2.IMREAD_GRAYSCALE) r.set('name','tangming') r.set('age',5) # 3. store the encoded array under supplied key r.set('image',toRedis(img)) print(r.get('name')) print(r.get('age')) array = fromRedis(r.get('image')) cv2.imshow('image',array) 2 Redis C++编程用C++来操作Redis数据库，需要另外的Redis客户端库，常用的有hiredis、xredis和cpp_redis。hiredis使用简单，函数少，最接近Redis原始命令。cpp_redis需要C++11编译器的支持。 参考文献 &amp; 资源链接 Python使用struct处理二进制]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Redis</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型]]></title>
    <url>%2F2019%2F10%2F16%2Fredis-data-types%2F</url>
    <content type="text"><![CDATA[作为key-value型数据库，Redis也提供了键和值的映射关系。除了常规的数值和字符串，Resis的值还可以是Lists，Sets，Sorted Sets,Hashes。值的数据类型决定了该键值支持的操作。Redis 支持诸如列表、集合或有序集合的交集、并集、查集等高级原子操作；同时，如果值的类型是普通数字，Redis则提供自增等原子操作。 1. Strings字符串是Redis最基本的数据类型。Redis字符串是二进制安全的，这意味着Redis字符串可以包含任何类型的数据，例如JPEG图像或序列化的Ruby对象。一个字符串值允许存储的最大容量为512MB。利用字符串可以进行以下操作： 利用INCR系列命令将Strings用作原子计数器 利用APPEND命令在字符串的末尾添加值 利用GETRANGE和SETRANGE命令对字符串中的部分字符进行修改和查询 利用GETBIT和SETBIT命令对字符串进行位操作字符串是其他四种数据类型的基础，其他数据类型和字符串的差别在于组织字符串的形式不同。 2. ListsRedis的列表就是一个简单的字符串列表，按照插入顺序排序。通过LPUSH命令将新元素插入到列表的头部，通过RPUSH将新元素插入到列表的尾部。Redis列表最多可容纳$2^{32}-1$个元素。Redis列表使用双向链表实现的，主要特点是，无论列表有多大，在列表头部和尾部插入和删除元素耗费的时间是一样的。访问列表两端的元素速度非常快，但是访问列表中间位置的元素非常耗时间，是其时间复杂度为$O(N)$。对列表进行的主要操作有： LPUSH和RPUSH向列表两端插入元素，LPOP和RPOP从列表两端弹出元素 LRANG获取特定索引范围的列表片段，LTRIM删除索引以外的元素 LINDEX和LSET用来索引/设置指定索引位置的元素 LREM用来移除列表中特定数量的元素，&gt;0从左边删除，&lt;0从右边删除，=0删除列表中特定值的所有元素 3. SetsRedis集合是无序的字符串集合，Redis集合使用值为空的散列表实现，所以插入、删除、检测元素是否存在的时间复杂度都是$O(1)$。Redis集合最多可容纳$2^{32}-1$个元素。对集合进行的主要操作有： SADD和AREM进行元素的增加/删除 进行快速的集合运算，SDIFF求差集，SINTER求交集，SUNION求并集。 4. Hashes Redis是采用字典结构以key-value的形式存储数据的，Hhash的value也是一种字典结构，其存储了字段(field)和字段值(field value)的映射，但字段值只能是字符串，Hash的这种结构很适合存储对象数据。每个Hash最多只能存储$2^{32}-1$个key-value对。 5. Sorted Sets与Redis集合类似，Redis有序集合是非重复的String集合。 区别在于，有序集合的每个成员都有一个分数，该分数用于从最小到最大进行排序。 虽然成员是唯一的，但分数可能会重复。有序集合类型是使用散列表和跳跃表(Skip list)实现的，所以即使读取位于中间部分的数据速度也很快，时间复杂度是$O(logN)$。有序集合不仅可以非常快的进行元素的增删查改，因为元素是顺序排序的，所以可以获取特定范围的元素。 6. 其他Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 Redis中还可以存储数值和二进制数据。如果使用Redis存储图像这类数据，就要将图像数据序列化成二进制数据。序列化就是将程序数据转化成能被存储并传输的格式的过程，它的逆过程称为反序列化。 参考文献 &amp; 资源链接 Storing complex data structures in Redis Data types An introduction to Redis data types and abstractions]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++序列化库—Cereal]]></title>
    <url>%2F2019%2F10%2F16%2Fcpp-serialization-cereal-introduction%2F</url>
    <content type="text"><![CDATA[Cereal是一个开源的、轻量级的跨平台序列化库。cereal只包含头文件，不依赖任何三方库，易于使用。Cereal可以将任意的数据类型序列化成二进制、XML格式或者JSON。 Cereal使用非常简单，只需要包含头文件以及为需要序列化的数据编写一个序列化函数即可，会寻找定义在数据结构中serialization函数。使用Cereal进行序列化主要分为两个步骤：定义对象数据的序列化函数，以及对象数据的序列化。 1. Cereal序列化函数Cereal支持单独使用serialization函数，或者分别使用load/save函数进行序列化。序列化函数既可以定义在数据的外部，也可以定义在内部。 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;string&gt;/*内部serialization函数*/struct Student&#123; std::string name; int age; template&lt;calss Archive&gt; void serialize(Archive &amp;archive) &#123; archive(name, age); &#125;&#125;;/*外部serialization函数*/struct Student&#123; std::string name; int age;&#125;;template&lt;calss Archive&gt;void serialize(Archive &amp;archive, Student &amp;stu)&#123; archive(stu.name, stu.age);&#125; NOTE：序列化函数也可以私有化，但是必须声明Cereal为友元，因为序列函数私有化之后无法从外部访问，只能通过cereal::access进行访问。 123456789101112131415#include &lt;cereal\access.hpp&gt; // 必须class Student&#123; friend class cereal::access; // 必须private: template&lt;calss Archive&gt; void serialize(Archive &amp;archive) // 私有函数，无法从外部访问 &#123; archive(name, age); &#125; std::string name; int age;&#125; NOTE：如果使用load/save函数进行序列化，save函数必须是const类型，否则Cereal会报错。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;string&gt;/*内部serialization函数*/struct Student&#123; std::string name; int age; template&lt;calss Archive&gt; void save(Archive &amp;archive) const // const &#123; archive(name, age); &#125; template&lt;calss Archive&gt; void load(Archive &amp;archive) &#123; archive(name, age); &#125;&#125;;/*外部serialization函数*/struct Student&#123; std::string name; int age;&#125;;template&lt;calss Archive&gt;void save(Archive &amp;archive, Student const &amp;stu) // const&#123; archive(stu.name, stu.age);&#125;template&lt;calss Archive&gt;void save(Archive &amp;archive, Student &amp;stu)&#123; archive(stu.name, stu.age);&#125; 2. Cereal数据序列化Cereal支持二进制、XML和JSON三种格式的读写操作，在使用时包含对应的头文件。 1234#include &lt;cereal\archives\binary.hpp&gt; // 二进制#include &lt;cereal\archives\portable_binary.hpp&gt; // 顺序二进制#include &lt;cereal\archives\xml.hpp&gt;#include &lt;cereal\archives\json.hpp&gt; Cereal的读写操作是基于C++的std::ostream和std::istream。这意味着，操作对象可以是文件、内存流，甚至标准的输入输出。以下代码实现的是对cv::Mat序列化，序列化函数为Serialising OpenCV matrices using boost and cereal。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;cereal\archives\binary.hpp&gt;#include &lt;opencv2\core.hpp&gt;#include &lt;opencv2\highgui.hpp&gt;#include "matserialization.h"#ifdef _DEBUG#pragma comment(lib,"opencv_world346d.lib")#else#pragma comment(lib,"opencv_world346.lib")#endifint main()&#123; cv::Mat image = cv::imread("../../data/imgs/panda.bmp", cv::IMREAD_GRAYSCALE); std::stringstream str; &#123; // 使用大括号来限定序列化类的生存范围 cereal::BinaryOutputArchive oarchive(str); oarchive(image); &#125; // Cereal存储类自动销毁，完成序列化操作 cv::Mat image_loaded; &#123; cereal::BinaryInputArchive iarchive(str); iarchive(image_loaded); &#125; system("pause"); return 0;&#125; NOTE：Cereal的工作方式是RAII规范，即只有在存储类被销毁时，才能完全保证完全输出。 3. Cereal与boost.SerializationCereal和Boost很相似。这是因为Cereal被设计时就考虑了Boost用户的使用习惯，模仿了许多Boost序列化库的语法习惯。Cereal和Boost序列库的接口非常相似，在一些情况下可以非常迅速的将Boost库替换成Cereal。但是即便如此，Cereal和Boost还是有很大的区别。 cereal在保存数据时会存储尽可能少的元数据。 Boost默认情况下会存储有关库版本以及类型本身的各种元数据。 cereal只需要头文件，不依赖任何三方库或者平台。boost的库非常多，而且需要考虑不同机器之间的版本问题。 cereal支持几乎所有的标准库，cereal支持而boost不支持的包括：&lt;forward_list&gt;，&lt;memory&gt;，&lt;queue&gt;，&lt;stack&gt;，&lt;tuple&gt;，&lt;unordered_set&gt;和&lt;unordered_map&gt;。 cereal更加简洁。例如，在Cereal中当把serialize函数分成load/save函数时，不需要提前使用宏声明。Cereal还使用了static_assert，提供了更加准确的错误提示。 cereal和boost使用不同的语法进行序列化。boost使用的是&amp;，&lt;&lt;和&gt;&gt;，cereal使用的是()。 参考文献 &amp; 资源链接 Cereal Library系列教程 Serialising OpenCV matrices using boost and cereal Transitioning From Boost]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>序列化</tag>
        <tag>Cereal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++序列化]]></title>
    <url>%2F2019%2F10%2F16%2Fcpp-serialization-introduction%2F</url>
    <content type="text"><![CDATA[在程序中往往需要将程序中的某些数据存储在内存中，然后将其写入本地文件或者进行网络传输。将程序数据转化成能被存储和传输的格式的过程称为序列化，它的逆过程称为反序列化。 以下为一个简单的C++序列化程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;string&gt;struct Student&#123; std::string name; int age;&#125;;int Serialize(const Student &amp;stu, char out[])&#123; int count = 0; memcpy(out, stu.name.c_str(), stu.name.length()); count += stu.name.length(); memcpy(out + count, &amp;stu.age, sizeof(int)); count += sizeof(int); return count;&#125;int Deserialize(Student &amp;stu, const char* in, int count)&#123; int offset = 0; stu.name.append(in, count - sizeof(int)); offset += stu.name.length(); memcpy(&amp;stu.age, in + offset, sizeof(int)); return 0;&#125;int main()&#123; char buf[128]; int count = 0; Student stu1; stu1.name = "tangming"; stu1.age = 1024; count = Serialize(stu1, buf); Student stu2; Deserialize(stu2, buf, count); std::cout &lt;&lt; "name: " &lt;&lt; stu2.name &lt;&lt; std::endl; std::cout &lt;&lt; "age: " &lt;&lt; stu2.age &lt;&lt; std::endl; system("pause"); return 0;&#125; C++中常用的序列化方法主要有protobuf和Boost.Serialization。Google Protocol Buffers(protobuf)是Google内部使用的数据编码方式，用来替代XML进行数据交换。protobuf效率较高，但是数据对象必须预先定义，并使用protoc编译，适合要求效率，允许自定义类型的内部场合使用。Boost.Serialization可以创建或重建程序中的等效结构，并保存为二进制数据、文本数据、XML或者有用户自定义的其他文件。Boost.Serialization使用灵活简单，而且支持标准C++容器。 参考文章 &amp; 资源链接 最常用的两种C++序列化方案的使用心得]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intel MKL简介]]></title>
    <url>%2F2019%2F10%2F15%2Fmath-mkl-introduction%2F</url>
    <content type="text"><![CDATA[MKL是Intel公司出品的数学函数计算库，提供经过高度优化和大量线程化处理的计算函数，有C和Fortran接口。 MKL主要包含的内容如下： 基本线性代数子系统 稀疏基本线性代数子系统 线性代数库 可扩展线性代数库 稀疏求解器 矢量数学库 矢量统计库 傅里叶变换库 集群傅里叶变换库 1. BLASBLAS是基本线性代数子系统，提供向量与向量、向量与矩阵以及矩阵与矩阵的运算。BLAS Level1提供向量数据的加减、点乘等；BLAS Level2提供向量与举证的运算，如乘法运算；BLAS Level3提供矩阵与矩阵的运算，比如矩阵乘法。BLAS函数名结构为：&lt;character&gt;&lt;name&gt;&lt;mod&gt;()其中**&lt;character&gt;**表示代表数据类型： 参数 描述 s real, single precision c complex, single precision d real, double precision x complex, double precision 在BLAS Level1中，**&lt;name&gt;**表示的是运算的方式，如dot表示向量点乘，swap表示向量交换。在BLAS Level2和BLAS Level3中，**&lt;name&gt;**表示矩阵的类型。 参数 描述 ge 一般矩阵(general matrix) sb (general band matrix) sy (symmetric matrix) sp (symmetric matrix package storage) sb (symmetric band matrix) he (Hermitian matrix) hp (Hermitian matrix package storage) hb (Hermitian band matrix) tr (triangular matrix) tp (triangular matrix package storage) tb (triangular band matrix)]]></content>
      <categories>
        <category>数学计算</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数学计算库汇总]]></title>
    <url>%2F2019%2F10%2F15%2Fmath-library-introduction%2F</url>
    <content type="text"><![CDATA[对于机器学习的很多问题来说，计算的瓶颈在于大规模以及频繁的矩阵预算。为了使机器学习算法运行得更高效，需要在代码中采用比较成熟的矩阵运算数学库。本文主要总结常见的矩阵运算库。 1. 基本数学库1.1 BLAS(Basic Linear Algebra Subprograms)BLAS是一个API标准，用以规范发布基础线性代数操作的数值库。Netlib用Fortran实现了BLAS的API接口，得到的库就叫BLAS。 1.2 LAPACK(Linear Algebra PACKage)LAPACK也是由Netlib用Fortran语言编写的，底层是BLAS，但是LAPACK的运行效率更高。LAPACK提供了丰富的工具函数用于矩阵运算，如解多元线性方程、线性方程组的最小平方解、计算特征向量、奇异值分解等。 2. 高级数学库2.1 EIGENEigen是一个线性算术的C++模板库，支持多平台，直接包含头文件就可以使用。TensorFlow就是基于Eigen的。底层： BLAS/LAPACK：支持所有基于F77的BLAS或LAPACK作为底层(EIGEN_USE_BLAS、EIGEN_USE_LAPACK) MKL：支持MKL作为底层(EIGEN_USE_MKL_ALL) CUDA：支持在CUDA kernels里使用CUDA OpenMP：多线程优化 2.2 Intel MKL(Math Kernel Library)MKL基于Intel C++和Fortran编译器构建而成，并利用OpenMP实现了线程化。MKL的算法能够平均分配数据和任务，充分利用多个核心和处理器，支持Windows/Linux。底层： BLAS/LAPACK BLACS：Basic Linear Algebra Communication Subprograms ScaLAPACK：面向集群的LAPACK分布式内存并行版本 DFTs：离散傅里叶变换 VML：矢量数学库 VSL：矢量统计学库 PDF：偏微分方程 BRNGs：Basic Random Number Generators 2.3 ACML(AMD Core Math Library)对于Intel CPU，使用MKL能获得较好的运算性能，而对于AMD CPU，使用的是ACML。在矩阵运算方面，ACML底层使用的也是BLAS,LAPACK等。底层： BLAS/LAPACK：针对AMD进行了优化 FFTs：快速傅里叶变化 RNG：随机数生成器 2.4 OpenBLASOpenBLAS是一个高性能多核 BLAS 库 2.5 CUDA Math LibraryCUDA Math Library是在GPU上的数学计算库，其计算性能远高于CPU上的数学计算库。底层： CUBLAS：是一个基于GPU的BLAS库，提供的计算函数都在GPU上执行。]]></content>
      <categories>
        <category>数学计算</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++编程—断言(Assert)]]></title>
    <url>%2F2019%2F10%2F15%2Fcpp-assert%2F</url>
    <content type="text"><![CDATA[断言是指在开发期间使用的、让程序运行时进行自检的代码。断言为真，表示程序运行正常，断言为假，则意味着程序中出现了意料之外的错误。 一个断言通常含有两个参数：一个描述假设为真时的布尔表达式，一个断言为假时需要显示的信息。C++标准中的assert宏并不支持文本信息，可以使用C++宏改进ASSERT。 123456789#define ASSERT(condition, message)&#123; if(!(condition)) &#123; LogError("Assert failed:", #condition, message); exit(EXIT_FAILURE); &#125;&#125; 频繁的调用asset()会极大影响程序的性能，增加额外的开销。在调试结束以后，可以通过在包含#include &lt;assert.h&gt;的语句前插入#define NDEBUG来禁用assert()调用。 1234567891011#ifdef _DEBUG #define ASSERT(condition) if(!(condition)) &#123; fflush(stdout); fprintf(stderr,"\nAssert failed:%s, lint %u\n",__FILE__, __LINE__); &#125; #else#define ASSERT(condition) NULL#endif 参考文献 &amp; 资源链接 断言assert函数]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis C++客户端—Hiredis]]></title>
    <url>%2F2019%2F10%2F14%2Fredis-hiredis-introduction%2F</url>
    <content type="text"><![CDATA[Hiredis是Redis数据库一个轻量的C语言客户端库。它只是简单的提供了对redis操作语句支持的接口，并没有实现具体的操作语句的功能，因此可以很容易的使用该库和redis数据库进行交互。 1. Hiredis编译Hiredis是用C写的Redis客户端，对Redis协议进行了简单的封装。除了支持发送命令和接收应答外，Hiredis还提供了独立于I/O的数据流解析操作，用于解析应答数据。在Windows平台上使用Hiredis，一般需要将源码编译生成库文件然后进行调用。在Visual Studio上编译Hiredis项目的时候会出现无法生成lib的问题，其Github库的issues#687提供了一种解决方案，测试可行。 同步连接：服务器与第一个请求建立连接并通信以后，第二个请求会被阻塞。异步连接：服务器可以同时响应多个请求 Hiredis提供了同步、异步以及回复解析三种API。 2. 同步API常用的同步API的函数有： 123redisContext *redisConnect(const char *ip, int port);void *redisCommand(redisContext *c, const char *format, ...);void freeReplyObject(void *reply); 2.1 连接2.2 发送命令2.3 处理应答2.4 清理连接2.5 发送多个命令2.6 管线2.7 错误处理参考文献 &amp; 资源链接]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Hiredis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[形态学变换]]></title>
    <url>%2F2019%2F10%2F12%2Fcv-morphological-transformations%2F</url>
    <content type="text"><![CDATA[形态学变换主要是对二值图像进行处理，需要两个参数：原始图像，以及结构元。结构元决定了操作的性质，基本的操作为腐蚀和膨胀，他们的变体构成了开运算，闭运算等。 1. 腐蚀把前景物体的边界腐蚀掉，但是前景仍然是白色的。卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是1，那么中心元素就保持原来的像素值，否则就变为零。根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪音很有用，也可以用来断开两个连在一块的物体。 123456789# Pythonimport cv2import numpy as npkernel = np.ones((5,5),np.uint8)erosion = cv2.erode(img,kernel,iterations=1)# C++kernel = getStructuringElement(shape,kernel_size[,anchor]);// shape:MORPH_RECT/MORPH_CROSS/MORPH_ELLIPSEerode(src,dst,kernel); 2. 膨胀与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是1，中心元素的像素值就是1。所以这个操作会增加图像中白色区域（前景）。一般在去噪音时先腐蚀再膨胀，因为腐蚀再去掉白噪音的同时，也会使前景对象变小，所以我们再膨胀。这时噪音已经被去除，不会再回来了，但是前景还在并会增加，膨胀也可以用来连接两个分开的物体。 12345# Pythondilation = cv2.dilate(img,kernel,iterations=1)# C++dilate(src,dst,kernel); 3. 开运算先进行腐蚀再进行膨胀就叫做开运算，用来去除噪声。 12345# Pythonopening = cv2.morpologyEx(img,cv2.MORPH_OPEN,kernel)# C++morpologyEx(src,dst,MORPH_OPEN,kernel); 4. 闭运算先腐蚀后膨胀，用来填充前景物体上的小洞。 12345# Pythonclosing = cv2.morpologyEx(img,cv2.MORPH_CLOSE,kernel)# C++morpologyEx(src,dst,MORPH_CLOSE,kernel); 5. 形态学梯度膨胀图与腐蚀图之差。 12345# Pythongradient = cv2.morpologyEx(img,cv2.MORPH_GRADIENT,kernel)# C++morpologyEx(src,dst,MORPH_GRADIENT,kernel); 6. 顶帽运算原图像与开运算之差。 12345# Pythontophat = cv2.morpologyEx(img,cv2.MORPH_TOPHAT,kernel)# C++morpologyEx(src,dst,MORPH_TOPHAT,kernel); 7. 黑帽运算闭图像与原图像之差。 12345# Pythonblackhat = cv2.morpologyEx(img,cv2.MORPH_BLACKHAT,kernel)# C++morpologyEx(src,dst,MORPH_BLACKHAT,kernel);]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Visual Studio编程问题集锦]]></title>
    <url>%2F2019%2F10%2F12%2Fvs-programming-errors-summary%2F</url>
    <content type="text"><![CDATA[本文主要记录Visual Studio使用过程中出现的问题以及相应的解决方法。 1. 编译 模块计算机类型 x64 与目标计算机类型 x86 冲突 出现此问题要在三个的地方进行确认： 项目右键-&gt;属性-&gt;链接器-&gt;高级-&gt;目标计算机：设置为MachineX64 (/MACHINE:X64) 项目右键-&gt;属性-&gt;链接器-&gt;命令行-&gt;其他选项：设置为/machine:X64 VS菜单栏-&gt;生成-&gt;配置管理器-&gt;活动解决方案平台：设置为x64 NOTE: 在进行一些开源项目的编译时，属性菜单中没有链接器 的属性，但是有库管理器 属性，可以在该属性下配置目标计算机和命令行的值。]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis简介]]></title>
    <url>%2F2019%2F10%2F12%2Fredis-introduction%2F</url>
    <content type="text"><![CDATA[Redis 是一个key-value存储系统，本文主要记录Redis的安装、配置、数据类型以及基本操作。 Redis(Remote Dictionary Server)是一个开源的高性能key-value数据库，它以字典结构存储数据，并允许其他应用通过TCP协议进行读取。Redis的数据都存储在内存中，因此在性能上相比较于硬盘存储的数据库有非常明显的优势。 1. Redis的安装1.1 Windows平台官网的Redis只有Linux版本的，但是Github上有Windows版的Redis【下载地址】。Windows的Redis有msi安装版，压缩包版和源码编译三种使用方式。 Redis的目录下主要有两类文件：应用文件和配置文件。 文件名 文件功能 redis-server 服务端应用，提供Redis服务 redis-cli 客户端程序，通过连接Redis服务并进行操作 redis-benchmark 性能测试，用来模拟同时由N个客户端发送M个SETs/GETs操作 redis-check-aof 更新日志检查 redis-check-dump 本地数据库检查 redis.windows.conf 配置文件，将Redis作为普通软件使用，命令行关闭则Redis关闭 redis.windows-service.conf 配置文件，将Redis作为系统服务进行配置 2. 配置和使用2.1 服务端命令Redis安装完成后需要进行启动才能使用，打开命令行，输入redis-server redis.windows.conf命令，即可启动Redis服务： 12345678910111213141516171819202122C:\Redis&gt;redis-server redis.windows.conf _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 3.2.100 (00000000/0) 64 bit.-`` .-```. ```\/ _.,_ &apos;&apos;-._( &apos; , .-` | `, ) Running in standalone mode|`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6379| `-._ `._ / _.-&apos; | PID: 6660`-._ `-._ `-./ _.-&apos; _.-&apos;|`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;|| `-._`-._ _.-&apos;_.-&apos; | http://redis.io`-._ `-._`-.__.-&apos;_.-&apos; _.-&apos;|`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;|| `-._`-._ _.-&apos;_.-&apos; |`-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos;[6660] 12 Oct 11:17:05.019 # Server started, Redis version 3.2.100[6660] 12 Oct 11:17:05.028 * DB loaded from disk: 0.007 seconds[6660] 12 Oct 11:17:05.029 * The server is now ready to accept connections on port 6379 可以看到Redis已经打开了，使用这种方式的缺点是不能关闭命令行，否则Redis服务就会关闭。如果要开机启动Redis服务，需要将Redis安装成Windows服务。 12345678# 安装服务redis-server --service-install redis.windows.conf # 启动服务redis-server --service-start # 停止服务redis-server --service-stop # 卸载服务redis-server --service-uninstall 两种启动服务的方式根据个人喜好，或者基于开发环境或生产环境进行选择。 2.2 客户端命令另外打开一个命令行窗口，输入客户端使用命令redis-cli -h host -p port -a password就可以连接到Redis服务,host默认为127.0.0.1,port默认为6379。 1234567891011121314151617# 连接数据库服务C:\Redis&gt;redis-cli -h 127.0.0.1 -p 6379 #命令行输入127.0.0.1:6379&gt;# 写入数据127.0.0.1:6379&gt; set key value# 查询数据127.0.0.1:6379&gt; get key# 判断是否存在127.0.0.1:6379&gt; exists key# 删除127.0.0.1:6379&gt; del key# 查询数据类型127.0.0.1:6379&gt; type key# 关闭Redis服务127.0.0.1:6379&gt; shutdown# 数据库选择127.0.0.1:6379&gt; select db_num 2.3 Redis配置文件属性Redis配置文件中可以对数据库的属性进行配置，常用的配置参数如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445################################## NETWORK ######################################默认ip地址bind 127.0.0.1#Redis默认监听端口port 6379#客户端闲置多少秒后断开连接timeout 0################################# GENERAL ######################################是否作为守护进程运行,windows下不支持该属性daemonize no#日志显示级别loglevel notice#指定日志输出的文件名，默认输出到标准输出端口logfile &quot;&quot;#默认支持的数据库的数量databases 16################################ SNAPSHOTTING #################################持久化策略save &lt;seconds&gt; &lt;changes&gt;save 100 1 #当有一条数据被改变时，900s刷新到disk一次save 300 10 #当有10条数据被改变时，300s刷新到disk一次save 60 10000 #当有10000条数据被改变，60s刷新到disk一次#持久化数据保存的文件名dbfilename dump.db#持久化数据保存的路径dir ./################################# REPLICATION ##################################主从配置，设置该数据库为其他的从数据库slaveof &lt;masterip&gt; &lt;masterport&gt;#主服务器连接时需要的密码masterauth &lt;master-password&gt; ################################## SECURITY ####################################设置连接密码requirepass &lt;password&gt;################################### LIMITS #####################################最大客户连接数maxclients 10000#persistence-available [(yes)|no]#可使用的最大最大内存maxmemory &lt;bytes&gt;############################## APPEND ONLY MODE ################################是否开启日志功能appendonly no#AOF持久化策略appendfsync [always|everysec|no] 3. Redis数据浏览器RedisClient这个工具是Redis的客户端，专门用来浏览当前Redis中的所有数据。省去了查询Redis里面有哪些数据还需要输入命令行的繁琐和不便利。RedisClient可以直接在Github上进行下载，支持Windows、Linux和MacOS。操作简单，功能也很全，Github仓库里有详细的使用说明。 4. Redis编程4.1 PythonPython使用Redis非常简单，可以通过pip install redis在环境中安装编程需要的API。下面是一个简单的实例，利用Redis存储数值、字符串和图像。 123456789101112131415161718192021222324252627282930313233343536import cv2import redisimport structimport numpy as npdef toRedis(array): ''' Encode ndarry 'array' to bytes ''' # 1. get shape of Numpy array and encode h,w = array.shape shape = struct.pack('&gt;II',h,w) # '&gt;'表示大端，'I'表示4个字节的unsigned int，'II'表示8字节的unsigned int # 2. append the Numpy array as bytes to the shape encode = shape+array.tobytes() return encodedef fromRedis(encode): # 4. extract the shape of the Numpy array from the string h,w = struct.unpack('&gt;II',encode[:8]) # extract data and repopulate Numpy array, reshape to original shape array = np.frombuffer(encode,dtype=np.uint8,offset=8).reshape(h,w) return arrayif __name__=='__main__': r = redis.Redis(host='127.0.0.1',port=6379) img = cv2.imread('./oil11_2.bmp',cv2.IMREAD_GRAYSCALE) r.set('name','tangming') r.set('age',5) # 3. store the encoded array under supplied key r.set('image',toRedis(img)) print(r.get('name')) print(r.get('age')) array = fromRedis(r.get('image')) cv2.imshow('image',array) 4.2 C++用C++来操作Redis数据库，需要另外的Redis客户端库，常用的有hiredis、xredis和cpp_redis。其中hiredis使用简单，函数少，最接近Redis原始命令。cpp_redis需要C++11编译器的支持。 参考文献 &amp; 资源链接 microsoftarchive-redis Java Redis Client GUI Tool Redis源码解析 redis入门 Windows C++ Redis客户端 cpp_redis]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis内存模型]]></title>
    <url>%2F2019%2F10%2F11%2Fredis-memory-model%2F</url>
    <content type="text"><![CDATA[本文主要记录Redis的内存模型，包括内存的使用情况、内存分配器、简单动态字符串以及不同对象类型在内存中的编码方式等。 1. 内存统计在客户端可以通过info命令查看内存的使用情况。 1234567891011121314151617127.0.0.1:6379&gt; info memory# Memoryused_memory:13293448 #Redis分配器分配的内存总量used_memory_human:12.68M #used_memory_rss:13256520 #Redis进程占据操作系统的内存，除了used_memory之外还有本身运行内存以及内存碎片等used_memory_rss_human:12.64Mused_memory_peak:25839504used_memory_peak_human:24.64Mtotal_system_memory:0total_system_memory_human:0Bused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionmem_fragmentation_ratio:1.00 #内存碎片比率mem_allocator:jemalloc-3.6.0 #Redis使用的内存分配器 Redis的内存占用主要分为以下几个部分： 数据：即使用键值对存储的数据，这部分内存统计在used_memory中 进程运行内存：Redis主进程本身运行需要的内存 缓冲内存：包括客户端缓冲内存、复制积压缓冲区、AOF缓冲区等。客户端缓冲内存存储客户端连接的输入输出缓冲；复制积压缓冲内存用于部分复制功能；AOF缓冲区用于进行AOF重写时保存最近的写入命令。 内存碎片：Redis再分配和回收物理内存过程中产生的无法有效利用的内存。 参考文献 &amp; 资源链接 如何阅读Redis源码 Redis设计与实现 Redis内存模型]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch模型]]></title>
    <url>%2F2019%2F10%2F09%2Fpytorch-model-introduction%2F</url>
    <content type="text"><![CDATA[本文主要记录PyTorch模型搭建，参数初始化,模型的保存和加载以及模型Fintune的相关内容。 1. 模型的搭建1.1 模型的定义PyTorch中进行模型定义需要注意的主要有三个部分： 模型类要继承nn.Module，让PyTorch知道这个类是模型类 在__init__()函数中定义模型需要用到的组件(如conv,pool,fc等) 在forward()函数中将定义的组件组装成需要的模型 1.2 nn.Sequetialtorch.nn.Sequetial是一个序列容器，能够将一系列的操作按照先后顺序封装起来，方便重复使用。 2. 模型权值的初始化模型定义完成后，通常还需要对模型的权值进行初始化之后才能开始训练。初始化的方法会直接影响到模型是否收敛。 2.1 权值初始化的流程权值的初始化分为两步： 定义一个初始化函数，在函数中设定什么层使用什么初始化方法，初始化方法在torch.nn.init中给出 实例化一个模型，执行该函数，即可完成初始化 2.2 常用的初始化方法PyTorch在torch.nn.init中提供了常用的初始化方法函数，主要分为两部分：Xavier,Kaiming系列和其他分布方法。 3. 模型Fintune一个良好的初始化权值可以加快模型的收敛，甚至可以提高模型的精度。在实际的应用中，我们通常用一个已经训练过的模型的权值作为模型的初始化参数，称之为模型Fintune，更广泛的叫做迁移学习。 Fintune的目的是让我们的新模型有一个较好的权重初始值，其流程主要分为三步： 训练并保存模型，得到一个预训练模型 加载模型，得到预训练模型的权值 初始化，将得到的权值对应放到新模型的不同层中 3.1 模型的保存和加载3.2 权值初始化]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CVPR2019医学图像处理论文集]]></title>
    <url>%2F2019%2F10%2F09%2Fpapers-about-medical-image-analysis-at-cvpr2019%2F</url>
    <content type="text"><![CDATA[参考文献 &amp; 资源链接 CVPR2019医学影像分析文集]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CUDA—内存模型]]></title>
    <url>%2F2019%2F10%2F09%2Fcuda-memory-model%2F</url>
    <content type="text"><![CDATA[现代计算机的内存结构主要有：寄存器(Registers)、缓存(Caches)、主存(Main Memory)和硬盘存储(Disk Memory)。速度最快的是寄存器，接着是缓存，然后是主存储器，常见的就是内存条，最后是硬盘。GPU和CPU的内存设计有着相似的准则和模型，CUDA编程模型将内存层次结构很好的呈现给开发者，让我们能显式的控制其行为。 GPU中内存设备有寄存器、共享内存、本地内存、常量内存、纹理内存、全局内存，各种内存都有自己的作用域、生命周期和缓存行为。 参考文章 &amp; 资源链接 CUDA内存模型概述]]></content>
      <categories>
        <category>CUDA编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CUDA—编程模型]]></title>
    <url>%2F2019%2F10%2F08%2Fcuda-programming-model%2F</url>
    <content type="text"><![CDATA[本文主要记录CUDA的内存分配、释放，主机与设备的数据传输，固定内存等内容 在标准的CUDA应用程序中，通常有以下几个步骤： 在Device上分配内存 将数据从Host复制到Device 在GPU上通过核函数对数据进行计算 将数据从Device复制到Host 释放分配的设备内存 其中，Device即GPU，Host即CPU，核函数即Kernel (the function that runs on GPU)。 1. 内存管理内存管理在串行程序中非常常见，寄存器和栈的内存由机器自己管理，堆空间由用户控制分配和释放。CUDA提供API可以分配管理Device上的内存，也可以管理Host上的内存。 标准C函数 CUDA C函数 说明 malloc cudaMalloc 内存分配 memcpy cudaMemcpy 内存复制 memset cudaMemset 内存设置 free cudaFree 内存释放 通常来讲，对于一维数组，在GPU中进行内存分配和数据拷贝使用的是cudaMalloc和cudaMemcpy函数，但是对于二维或者三维矩而言，使用cudaMalloc并不能得到最佳性能。原因是对于2D和3D内存，对齐是一个很重要的性质。cudaMallocPitch和cudaMalloc3D这两个函数能够保证分配的内存是合理对齐的，满足物理上的内存访问，可以确保对行进行访问的时候具有最优的效率。除此之外，对于数组内存的复制应当使用cudaMemcpy2D和cudaMemcpy3D来实现。 NOTE: cudaMallocPitch在分配行空间的时候会进行内存补齐，使得每一行的总的大小为128的整数倍，分配的总内存要大于实际所需的内存，我们在访问某一行的某个元素时，按照a[pitch*row+col]来访问。因此，在使用cudaMallocPitch的时候一定要返回pitch，只有这样才能访问二维数组的元素。当需要将这个二维数组从Device复制到Host的时候，如果使用cudaMemcpy不仅复制了数组的元素，也复制了补齐的内存，cudaMemcpy2D会跳过补齐的内存，只复制有效的数组元素。 2. Host/Device数据传输在CUDA应用的步骤中，数据的传输是必须的同时也是算法性能的瓶颈，相对于计算过程而言，数据的传输过程十分的耗费时间。优化数据传输的方式主要有三种： 尽量减少Host和Device之间数据的传输 使用CUDA内存优化技巧。比如Pinned Memory，Shared Memory，Constant Memory，使用流来掩盖内存延迟等【使用固定内存获得更高的数据传输带宽】 将多个小的数据传输合并为一次大的数据传输，这样可以消除每次传输的大部分开销 2.1 固定内存(Pinned Memory)在CPU与GPU协同计算过程中，主机内存默认时分页(pageable)内存，分页内存需要先转换为固定(Pinned)内存，然后进行主机与设备之间的内存拷贝。在CUDA C/C++中可以通过cudaMallocHost()或cudaHostAlloc()函数开辟固定内存并进行直接访问，从而提高Device和Host之间数据传输的效率。CUDA开辟的固定内存通过cudaFreeHost函数进行释放。 NOTE: 固定内存的分配有可能会失败，所以要进行错误检查。 12345cudaError_t status = cudaMallocHost((void**)&amp;h_PinnedMem, size);if(status != cudaSuccess)&#123; printf("Error in allocating pinned host memory");&#125; 2.2 合并小规模的数据传输因为每次传输都会产生额外的开销，所以最好将多个小规模的数据传输合并为单独的一次数据传输。可以使用临时的数组，然后将要传输的数据填充该数组，数组最好为固定内存的数组。 3. 核函数//TODO 参考文章 &amp; 资源链接 CUDA编程之快速入门 CUDA编程模型概述 Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA]]></content>
      <categories>
        <category>CUDA编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[医学图像处理资源汇总]]></title>
    <url>%2F2019%2F10%2F03%2Fawsome-medical-image-processing%2F</url>
    <content type="text"><![CDATA[汇总分类医学图像处理相关的数据、论文以及学习资源。 医学图像数据资源 Chest X-ray Dataset Open-Access Medical Image Repositories CVonline:Image Datebase–Biological/Medical CT-based Atlas of Head and Neck Cornell Vision and Image Analysis Group Public Databases Medical Imaging Datasets MICCAI2018 PET Radiomics Challenges TCIA Collections IXI Dataset OSSIS Data Mandibular CT Dataset Collection 甲状腺结节 Thyroid Segmentation in Ultrasonography Dataset DDTI:An open access database of thyroid ultrasound images TDID (Thyroid Digital Image Database)]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PyTorch简介]]></title>
    <url>%2F2019%2F10%2F03%2Fpytorch-introduction%2F</url>
    <content type="text"><![CDATA[PyTorch是基于torch的Python开源机器学习库，本文主要记录PyTorch的基本数据类型以及自动求导机制。 PyTorch是一个基于Python的科学计算包，主要提供以下两种服务： 作为NumPy的替代品，使用GPU的强大计算力（通过张量实现） 提供最大的灵活性和高速的深度学习研究平台（包含自动求导系统的深度神经网络） 1. 张量张量(Tensor)是PyTorch里面基础的运算单元，与NumPy的ndarry相同，都表示的是一个数据类型相同的多维矩阵。与ndarry的最大区别就是，Tensor可以在GPU上运行，ndarry只能在CPU上运行。张量本质上是一个矩阵，就存在着创建、索引、算数操作、逻辑操作以及维度操作等方法以及数据类型等属性。 1.1 基本类型Tensor的基本数据类型有五种： 32位浮点型 64位浮点型 16位整型 32位整型 64位整型除了数值类型外，还有byte型和char型。 2. 自动求导(Autograd)深度学习的算法本质是通过反向传播求导数，PyTorch的autograd的模块则实现了此功能。在Tensor上的所有操作，autograd都能为其自动提供微分，避免手动计算导数的复杂过程。在张量创建时，通过设置requires_grad为True来标识该张量需要进行自动求导，PyTorch会记录该张量的每一步操作并自动计算。 2.1 扩展Autograd如果需要自定义扩展autograd的功能，就需要扩展Function类。Function使用autograd来计算结果和梯度，并对操作历史进行编码。在Function类中，最重要的方法就是forward()和backward()，它们分别代表前向传播和后向传播。一个自定义的Function需要以下三个方法： __init__：Function的构造函数，其中定义操作需要的额外参数 forward()：执行前向传播的计算代码 backward()：执行后向传播的计算代码 NOTE: 方法必须是静态方法，所以在函数前面啊要加上@staticmethod。 参考文章 &amp; 资源链接 PyTorch学习笔记]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch数据的加载和预处理]]></title>
    <url>%2F2019%2F10%2F02%2Fpytorch-data-loader-and-preprocess%2F</url>
    <content type="text"><![CDATA[PyTorch通过torch.utils.data对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。torchvision中包含了常用的图像数据集，可以通过torchvision.datasets进行调用。 Pytorch读取图片的基本流程： 通过定义Dataset的子类定义如何通过索引读取图片及其标签； 通过DataLoder触发Dataset的子类去读取图片及其标签。 1. DatasetPyTorch读取图片，主要是通过Dataset类。Dataset作为所有datasets的基类存在，所有的datasets子类都需要继承它，并且实现__len__和__getitem__这两个成员函数，前者返回数据集的大小，后者支持对数据集进行整数索引。构建一个Dataset子类的基本流程： 1. __init__:初始化，在初始化函数中将准备好的获取图片的路径和标签存储到list中，其一个元素对应一个样本的路径和标签。初始化中还会初始化transform，transform是一个Compose类型，里面有一个list，其中定义了各种对图像进行处理的操作。 2. __getitem__:从list中获取图片的路径和标签，然后对图片进行读取，对图像进行预处理之后返回。 1234567891011121314import torch.utils.data as Datasetimport pandasclass MyDataset(Datasets): def __init__(self,csv_file,transform,target_transform): self.files = pandas.read_cvs(csv_file) # 获取图片数据的索引 self.transform = transform self.target_transform = target_transform def __getitem__(self,idx): # get a sample: img, label 获取图像和标签 if self.transform is not None: img = self.transform(img) return img,label def __len__(self): return len(self.files) 2. DataLoderDataset的子类主要定义了如何通过索引读取图片及其标签，以及对图片的预处理操作。但是，触发Dataset的读取操作是通过DataLoder实现的。DataLoder的参数有： dataset(Dataset)：加载的数据集 batch_size(int,optional’)：每个batch加载多少个样本 shuffel(bool,optional)：设置为True时每个epoch会打乱数据 sampler(Sampler,optional)：定义从数据集中提取样本的策略 num_workers(int,optional)：用多少个子进程加载数据 collate_fn(callable,optional) pin_memory(bool,optional) drop_last(bool,optional)：如果数据集不能被batch_size整除，，设置为True会删除最后一个不完整的batch。 3. torchvisiontorchvision是PyTorch中专门处理图像的库，其中包含了目前流行的图像数据集、模型结构和常用的图片转换工具。 3.1 torchvision.datasetstorchvision.datasets中包含了以下数据集：MNIST,COCO,LSUN Classification,ImageFolder,Imagenet-12,CIFAR10 and CIFAR100以及STL10。我们可以直接使用其中的数据集，示例如下： 123456import torchvision.datasets as datasetstrainset = datasets.MNIST(root='./data', # 表示MNIST数据的加载目录 train=True, # 表示是否加载数据库的训练集，false的时候加载测试集 tranform=None， # 是否对数据进行预处理 target_transform=None, download=True) # 表示是否自动下载MNIST数据集，并把数据集放在root下 3.2 torchvision.modelstorchvision中不仅提供了常用的图片数据集，还提供了训练好的模型，可以在加载之后直接使用。torchvision.models中包含的模型结构有AlexNet,VGG,ResNet,SqueezeNet及DenseNet。可以使用随机初始化的权重来创建这些模型，也可以使用预训练的模型。示例如下： 12345import torchvision.models as models# 随机初始化权重创建模型alexnet = models.AlexNet()# 使用预训练模型resnet18 = models.ResNet18(pretrained=True) 3.3 torchvision.transformstorchvision.transforms中提供了一般的图像转换操作，用于数据处理和数据增强。transform的方法主要分为四大类： 裁剪(Crop) 中心裁剪：transforms.CenterCrop(size) 随机裁剪：transforms.RandomCrop(size,padding=0) 随机裁剪再Resize：transforms.RandomResizedCrop(size,interpolation=2) 翻转和旋转(Flip and Rotation) 随机水平翻转：transforms.RandomHorizontalFlip 图像变换 标准化：transforms.Normalize(mean,std) 填充：transforms.Pad(padding,fill=0) 对transform操作 组合多个transform：transforms.Compose(transforms) 参考文章 &amp; 资源链接 PyTorch中文文档 PyTorch Handbook]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习资源汇总]]></title>
    <url>%2F2019%2F10%2F01%2Fawsome-deep-learning%2F</url>
    <content type="text"><![CDATA[汇总分类深度学习相关的数据、论文以及学习资源。 深度学习框架 Pytorch中文网 天池TIANCHI Awesome-PyTorch-Chinese Pytorch中文手册(pytorch-handbook) TensorFlow2.0 Handbook 论文及书籍资源数据资源代码资源]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C/C++编程—C程序的内存布局]]></title>
    <url>%2F2019%2F10%2F01%2Fcpp-memory-layout%2F</url>
    <content type="text"><![CDATA[C语言编写的程序经过编译、链接后，会形成一个格式统一的可执行文件，可执行文件只有放在计算机内存中才能够运行。程序的几个阶段最终会转化为内存中的几个区域，通常表示为“内存四区”——栈区、堆区、数据区和代码区(内存地址从高到低)。对于内存布局也有其他类型的描述，本质上是对数据区和代码区的子项按其他标准进行分类。 一个可执行文件分为映像和运行两种状态。在编译链接后形成的映像中，只包含代码段(Code)、只读数据段(RO data)和读写数据段(RW data)。在程序运行前的加载过程中，将动态生成未初始化数据段(BSS)，在程序运行时将动态生成堆(Heap)和栈(Stack)区域。 1. 静态区域(全局区域)1.1 代码段代码段由程序中执行的机器代码组成。在C语言中，程序语言进行编译后，形成机器代码。在程序执行过程中，CPU的程序计数器指向代码段的每一条机器代码，并由处理器依次运行。 1.2 只读数据段(RO data，即常量区)只读数据区存储的是程序中使用的一些不会被更改的数据，如字符串常量。程序运行结束后由系统进行释放。 1.3 读写数据段(RW data)存放已初始化的全局变量和静态变量（在程序生命周期中地址不变），这些变量占用存储器的空间，在程序执行时要位于可读写区域且被初始化。 1.4 未初始化数据段(BSS-Block Started by Symbol)未初始化数据是在程序声明，但是没有初始化的变量，这些变量在程序运行之前不需要占用存储器的空间。BSS段的变量只有名称和大小，没有值。 2. 动态区域2.1 堆(Heap) 堆内存只在程序运行时出现，一般由程序员分配和释放（C语言中使用malloc/free，C++中使用new/delete），区别于数据结构中的堆。 操作系统中有一个记录内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请的空间的堆结点，然后将该结点从链表中移除，并将该结点的内存分配给程序，多余的部分重新放回空闲链表中。 在windows下，堆是由低地址向高地址扩展的结构，是不连续的内存区域。 2.1 栈(Stack) 栈内存只在程序运行时出现，由系统编译器自动分配和释放，存放函数的参数值、内部的局部变量以及返回值等。 只要栈的剩余空间大于所申请的空间，系统将为程序提供内存。在windows下，栈是由高地址向低地址扩展的结构，是一块连续的内存区域。 参考文章 &amp; 资源链接 C程序的内存布局 C语言内存分布图]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习资源汇总]]></title>
    <url>%2F2019%2F09%2F30%2Fawsome-machine-learning%2F</url>
    <content type="text"><![CDATA[汇总分类机器学习相关的数据、论文以及学习资源。 学习资源 机器学习笔记 主要分为六个部分：激活函数、梯度下降、参数、正则化、模型介绍和使用技巧。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[C/C++资源汇总]]></title>
    <url>%2F2019%2F09%2F30%2Fawsome-c-and-cpp%2F</url>
    <content type="text"><![CDATA[汇总C/C++编程相关的数据、论文以及学习资源。 学习资源 C++11 FAQ中文版 C/C++语言和标准库参考]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉资源汇总]]></title>
    <url>%2F2019%2F09%2F30%2Fawsome-computer-vision%2F</url>
    <content type="text"><![CDATA[汇总分类计算机视觉相关的数据、论文以及学习资源。 图像和视频数据资源 CVonline:Image Datebase 学习资源 OpenCV-Python中文教程]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Github+Hexo搭建个人网站]]></title>
    <url>%2F2019%2F09%2F30%2Fhexo-building-personal-website%2F</url>
    <content type="text"><![CDATA[Hexo+Github应该是目前搭建个人博客使用最广的方式，本文主要记录利用Hexo+Github搭建静态博客以及一些配置相关的问题。 1. 准备工作 下载并安装node.js【下载地址】 安装node.js会默认安装npm，安装完成后，在命令行中输入命令验证Hexo的环境是否搭建完成。 12node -v # 输出node.js的版本号npm -v # 输出npm的版本号 下载安装git【下载地址】 2. 创建本地静态博客 新建一个文件夹用于存放blog文件 进入该文件夹内，使用npm命令安装Hexo，输入:npm install -g hexo-cli(下载静态网站的相关文件) 右键运行git，输入:hexo init(初始化静态网站的架构) 在命令行中输入命令，验证静态网站是否完成 12hexo generate # 本地生成静态文件hexo serve # 启动本地服务 打开浏览器，访问https://localhost:4000 3. 将博客与Github关联 在Github上创建yourname.github.io项目 打开本地blog文件夹内的_config.yml配置文件，并设置其中的deploy属性： 1234deploy: type: git repository: https://github.com/yourname/yourname.github.io.git branch: master 运行：npm install hexo-deployer-git --save 运行：hexo generate 运行：hexo deploy # 将本地静态文件发布到Github打开浏览器，访问https://yourname.github.io 参考文章 &amp; 资源链接 Hexo官方网站 NexT主题 Next主题增加Gitment评论系统 Hexo Next主题博客功能完善 Markdown入门参考 最完美的Hexo多电脑同步方法 Hexo博客搭建之在文章中插入图片]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
  </entry>
</search>
